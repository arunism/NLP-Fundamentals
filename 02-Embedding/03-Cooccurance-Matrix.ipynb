{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Co-occurance Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally speaking, a co-occurrence matrix will have specific entities in rows (ER) and columns (EC). The purpose of this matrix is to present the number of times each ER appears in the same context as each EC. As a consequence, in order to use a co-occurrence matrix, you have to define your entites and the context in which they co-occur.\n",
    "\n",
    "In NLP, the most classic approach is to define each entity (ie, lines and columns) as a word present in a text, and the context as a sentence.\n",
    "\n",
    "*Consider the following text:*\n",
    "> Roses are red. Sky is blue.\n",
    "\n",
    "With the classic approach described before, we'll have the following matrix:\n",
    "\n",
    "|| Roses | are | red | Sky | is | blue |\n",
    "| :- | :-: | :-: | :-: | :-: | :-: | :-: |\n",
    "| Roses | 1 | 1 | 1 | 0 | 0 | 0 |\n",
    "| are | 1 | 1 | 1 | 0 | 0 | 0 |\n",
    "| red | 1 | 1 | 1 | 0 | 0 | 0 |\n",
    "| Sky | 0 | 0 | 0 | 1 | 1 | 1 |\n",
    "| is | 0 | 0 | 0 | 1 | 1 | 1 |\n",
    "| Blue | 0| 0 | 0 | 1 | 1 | 1 |\n",
    "\n",
    "Here, each cell indicates wether the two items co-occur or not. You may replace it with the number of times it appears, or with a more sophisticated approach. You may also change the entities themselves, by putting nouns in columns and adjective in lines instead of every word.\n",
    "\n",
    "`What are they used for in NLP?` The most evident use of these matrix is their ability to provide links between notions. Let's suppose you're working on products reviews. Let's also suppose for simplicity that each review is only composed of short sentences. You'll have something like that:\n",
    "\n",
    "> Product X is amazing.<br/>I hate product Y.\n",
    "\n",
    "Representing these reviews as one co-occurrence matrix will enable you associate products with appreciations.\n",
    "\n",
    "*[[Source]](https://stackoverflow.com/questions/24073030/what-are-co-occurence-matrixes-and-how-are-they-used-in-nlp)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus = [\n",
    "    'Product X is amazing.',\n",
    "    'I hate product Y.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(sentences):\n",
    "    result = list()\n",
    "    for sentence in sentences:\n",
    "        table = str.maketrans('', '', string.punctuation)\n",
    "        sentence = sentence.translate(table).lower()\n",
    "        sentence = re.sub(' +', ' ', sentence).lstrip().rstrip()\n",
    "        result.append(sentence)\n",
    "    return result\n",
    "\n",
    "def update_matrix(sent, feats, matrix, window_len):\n",
    "    words = sent.split(' ')\n",
    "    for focus_word_idx, focus_word in enumerate(words):    # Iterate each word as focus word\n",
    "        focus_word = focus_word.lower()\n",
    "        x = max(0, focus_word_idx - window_len)\n",
    "        y = min(len(words), focus_word_idx + window_len + 1)\n",
    "        for context_word_idx in range(x, y):\n",
    "            if words[context_word_idx] in feats:\n",
    "                matrix_row_idx = feats.index(focus_word)\n",
    "                matrix_col_idx = feats.index(words[context_word_idx])\n",
    "                matrix[matrix_row_idx][matrix_col_idx] += 1\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 1. 0. 1. 0.]\n",
      " [0. 1. 1. 0. 1. 0. 1.]\n",
      " [0. 1. 1. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 1. 1. 1. 0.]\n",
      " [0. 1. 1. 1. 2. 1. 1.]\n",
      " [1. 0. 0. 1. 1. 1. 0.]\n",
      " [0. 1. 0. 0. 1. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "corpus = clean(corpus)\n",
    "vectorizer = CountVectorizer(stop_words=None, token_pattern=r\"(?u)\\b\\w+\\b\")\n",
    "vec = vectorizer.fit_transform(corpus)\n",
    "features = vectorizer.get_feature_names()\n",
    "n = len(features)\n",
    "window_len = 2\n",
    "matrix = np.zeros((n, n))   # Initialize co-occurance matrix to 0\n",
    "\n",
    "for sentence in corpus:\n",
    "    result = update_matrix(sentence, features, matrix, window_len)\n",
    "    \n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "65a9e37ffee3a5a10c5d687ae20c51ee3d4ba310e8eddff89fa7a028272d595a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
