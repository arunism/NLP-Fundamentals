{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Luong Attention\n",
    "\n",
    "Luong attention and Bahdanau attention are two of the most popular attention mechanisms used in machine translation. They are both based on the idea of weighting the importance of different words in the source sentence when generating the target sentence. However, there are some key differences between the two mechanisms.\n",
    "\n",
    "- **Computation of attention weights:** Bahdanau attention uses a neural network to compute the attention weights, while Luong attention uses a simpler mathematical approach.\n",
    "- **Type of similarity:** Bahdanau attention uses the dot product to calculate the similarity between the decoder's hidden state and the source states, while Luong attention can use either the dot product or the cosine similarity function.\n",
    "- **Scope of attention:** Bahdanau attention can attend to all of the source words, while Luong attention can only attend to a subset of the source words.\n",
    "\n",
    "In general, Luong attention is simpler and more efficient than Bahdanau attention. However, Bahdanau attention has been shown to be more effective in some cases.\n",
    "\n",
    "Here is a table summarizing the key differences between Luong attention and Bahdanau attention:\n",
    "\n",
    "| Feature | Luong attention | Bahdanau attention |\n",
    "| :-: | :-: | :-: |\n",
    "| Computation of attention weights | Mathematical approach | Neural network\n",
    "| Type of similarity | Dot product or cosine similarity | Dot product\n",
    "| Scope of attention | Subset of source words | All source words\n",
    "| Efficiency | More efficient | Less efficient\n",
    "\n",
    "Ultimately, the best choice of attention mechanism depends on the specific application. If efficiency is the most important factor, then Luong attention is a good choice. If accuracy is the most important factor, then Bahdanau attention may be a better choice."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
