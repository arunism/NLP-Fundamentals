{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbANObzZHMwa"
      },
      "source": [
        "# Bahdanau Attention (Additive Attention)\n",
        "\n",
        "One of the motivations behind Bahdanau Attention approach was the use of a fixed-length context vector in the basic encoderâ€“decoder approach. This limitation makes the basic encoder-decoder approach to underperform with long sentences. In basic encoder-decoder approach, the last element of a sequence contains the memory of all the previous elements and thus form a fixed-dimension context vector. But in case of Bahdanau attention approach:\n",
        "\n",
        "- First, we initialize the Decoder states by using the last states of the Encoder as usual\n",
        "- Then at each decoding time step:\n",
        "    - We use Encoder's all hidden states and the previous Decoder's output to calculate a Context Vector by applying an Attention Mechanism\n",
        "    - Lastly, we concatenate the Context Vector with the previous Decoder's output to create the input to the decoder.\n",
        "\n",
        "All the preprocessing steps will be same as that used in seq2seq model. Let's start by doing the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DebHB7L1HMwl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import math\n",
        "import torch\n",
        "import random\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from typing import Iterable, List\n",
        "from torch.utils.data import DataLoader\n",
        "from torchtext.datasets import Multi30k\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator as bvfi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pWXR-b3IQxJ"
      },
      "source": [
        "## Tokenization and Vocabulary Building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "weFs2tN-HMws"
      },
      "outputs": [],
      "source": [
        "SRC_LANG = 'de'\n",
        "TGT_LANG = 'en'\n",
        "specials = {'<UNK>': 0, '<PAD>': 1, '<SOS>': 2, '<EOS>': 3}\n",
        "\n",
        "tokenizer = dict()\n",
        "vocab = dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URLIdPHNIaqh"
      },
      "source": [
        "Create source and target language tokenizer. Make sure to install the dependencies.\n",
        "\n",
        "```\n",
        "pip install -U torchdata\n",
        "pip install -U spacy\n",
        "python -m spacy download en_core_web_sm\n",
        "python -m spacy download de_core_news_sm\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyHv9O2IIgwx"
      },
      "outputs": [],
      "source": [
        "# !pip install -U torchdata\n",
        "# !pip install -U spacy\n",
        "# !python -m spacy download en_core_web_sm\n",
        "# !python -m spacy download de_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofk_KjkFHMwy"
      },
      "outputs": [],
      "source": [
        "tokenizer[SRC_LANG] = get_tokenizer('spacy', language='de_core_news_sm')\n",
        "tokenizer[TGT_LANG] = get_tokenizer('spacy', language='en_core_web_sm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2Xx5E7bHMw1"
      },
      "outputs": [],
      "source": [
        "def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n",
        "    language_index = {SRC_LANG: 0, TGT_LANG: 1}\n",
        "\n",
        "    for data_sample in data_iter:\n",
        "        yield tokenizer[language](data_sample[language_index[language]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uzQBvm1HMw3"
      },
      "outputs": [],
      "source": [
        "for lang in [SRC_LANG, TGT_LANG]:\n",
        "    train_iterator, valid_iterator, test_iterator = Multi30k()    # Training data Iterator\n",
        "    vocab[lang] = bvfi(yield_tokens(train_iterator, lang), min_freq=1, specials=specials.keys(), special_first=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJ4WN8TeIxWM"
      },
      "source": [
        "Set token index (i.e. 0 here) as the default index. This index is returned when the token is not found. If not set, it throws RuntimeError when the queried token is not found in the Vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSj92VRsHMw4"
      },
      "outputs": [],
      "source": [
        "for lang in [SRC_LANG, TGT_LANG]:\n",
        "  vocab[lang].set_default_index(specials['<UNK>'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zxzPTDtI7_Q"
      },
      "source": [
        "## Encoder\n",
        "\n",
        "The encoder architecture is same as that used in seq2seq except the following two facts:\n",
        "- We will be using single layer of RNN\n",
        "- We will be using bidirectional RNN (forward + backward)\n",
        "\n",
        "As done in seq2seq, we initialize both forward and backward hidden states to a tensor of zeros. We get two context vectors one from each of forward and backward RNNs. However the decoder being unidirectional needs single context vector as input. To facilitate this we'll be concatinating two context vectors together."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMPI4J-NI6Ja"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(input_dim, emb_dim)\n",
        "        self.rnn = nn.LSTM(emb_dim, enc_hid_dim, bidirectional=True)\n",
        "        self.fc = nn.Linear(enc_hid_dim*2, dec_hid_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src):\n",
        "        embedding = self.dropout(self.embed(src))  # [len(src), batch_size, emb_dim]\n",
        "        output, hidden = self.rnn(embedding)\n",
        "        # outputs = [len(src), batch_size, hid_dim * n_directions]\n",
        "        # hidden = cell = [n layers * n directions, batch size, hid dim]\n",
        "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)))  # [batch_size, dec_hid_dim]\n",
        "        return output, hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqanje52epeI"
      },
      "source": [
        "## Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKBW3voeHMw5"
      },
      "outputs": [],
      "source": [
        "class BahdanauAttention(nn.Module):\n",
        "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
        "        super().__init__()\n",
        "        self.w1 = nn.Linear(dec_hid_dim, dec_hid_dim)\n",
        "        self.w2 = nn.Linear(enc_hid_dim, dec_hid_dim)\n",
        "        # self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
        "        self.v = nn.Parameter(torch.FloatTensor(dec_hid_dim).uniform_(-0.1, 0.1))\n",
        "        \n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QODTkb4OfhJX"
      },
      "source": [
        "## Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGGSNCO2HMw6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1J0mD_lwHMw6"
      },
      "source": [
        "## References\n",
        "\n",
        "- [The Power of Attention in Deep Learning](https://www.youtube.com/watch?v=Qu81irGlR-0)\n",
        "- [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/pdf/1409.0473.pdf)\n",
        "- [The Bahdanau Attention Mechanism](https://machinelearningmastery.com/the-bahdanau-attention-mechanism/#:~:text=The%20Bahdanau%20attention%20was%20proposed,mechanism%20for%20neural%20machine%20translation.)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
