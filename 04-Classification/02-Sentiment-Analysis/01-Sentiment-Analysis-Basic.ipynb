{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76iH-t2XBmd1"
      },
      "source": [
        "# Sentiment Analysis Basic\n",
        "\n",
        "Sentiment Analysis is a Natural Language Processing technique to identify if the textual data represents positive or negative or neutral sentiment. It is widely used in industry to understand customers through social reviews and comments.\n",
        "\n",
        "This notebook presents a basic introduction to sentiment analysis. The result obtained may not be quite good. The purpose of this notebook is to make you familiar with sentiment analysis technique. We will improvise the result in following notebooks later.\n",
        "\n",
        "The dataset used here is popular [IMDB review](http://ai.stanford.edu/~amaas/data/sentiment/) dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Ingestion"
      ],
      "metadata": {
        "id": "z163FTH0ALKI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import time\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchtext import data\n",
        "from torch.optim import Adam\n",
        "from torchtext.datasets import IMDB\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence"
      ],
      "metadata": {
        "id": "2AxXemlRBvWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torchdata\n",
        "# !pip install -U spacy\n",
        "# !python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "id": "a6M4K7UdAYN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_iterator, test_iterator = IMDB()"
      ],
      "metadata": {
        "id": "yqffYuYCAavY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing\n",
        "\n",
        "This step includes text cleaning tokenization and vocabulary building. I have created a basic workflow of text preparation here. If you want to play more with text preprocessing you can check the following techniques:\n",
        "\n",
        "- Apply minimum word occurance for vocabulary building\n",
        "- Word stemming and lemmatization"
      ],
      "metadata": {
        "id": "rLF8dZJ0Zoxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(text):\n",
        "  text = re.sub(r\"[-()\\\"#/@;:<>{}=~|.?,]\", \" \", text)\n",
        "  text = re.sub(' +', ' ', text)\n",
        "  return text.lower().split()\n",
        "\n",
        "\n",
        "tokens = list()\n",
        "for _, line in train_iterator:\n",
        "  tokens += tokenize(line)"
      ],
      "metadata": {
        "id": "EyqZ5TFiq_1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {'<PAD>':0, '<UNK>':1}\n",
        "for i, word in enumerate(set(tokens), start=len(vocab)):\n",
        "  vocab[word] = i"
      ],
      "metadata": {
        "id": "KRNZlmmFruCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def word_to_index(text):\n",
        "  return [vocab[word] if word in vocab.keys() else vocab['<UNK>'] for word in tokenize(text)]"
      ],
      "metadata": {
        "id": "HnsuH2TEfsRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining Model\n",
        "\n",
        "Model Implementation for Basic Sentiment Analysis using simple rnn. The dimension of each elements (in the form of tensors) are included within the square braces after the respective element."
      ],
      "metadata": {
        "id": "SqrFT86b99WU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentAnalysis(nn.Module):\n",
        "  def __init__(self, input_dim, embed_dim, hidden_dim, output_dim):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(input_dim, embed_dim)\n",
        "    self.rnn = nn.RNN(embed_dim, hidden_dim)\n",
        "    self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "  \n",
        "  def forward(self, data):  # [seq_len, batch_size]\n",
        "    self.embed = self.embedding(data)  # [seq_len, batch_size, embed_dim]\n",
        "    output, hidden = self.rnn(self.embed)\n",
        "    # output = [seq_len, batch_size, hid_dim]\n",
        "    # hidden = [1, batch_size, hid_dim]\n",
        "    logits = self.fc(hidden.squeeze(0))  # [batch_size, output_dim]\n",
        "    return logits"
      ],
      "metadata": {
        "id": "UTAdhSQ6iq44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`binary_accuracy` takes in two arguments: output predicted by our model and the actual output. This evaluation supports binary classification only."
      ],
      "metadata": {
        "id": "Vrk32Qx7T3me"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_accuracy(preds, y):\n",
        "  rounded_preds = torch.round(torch.sigmoid(preds))  # round predictions to closest integer\n",
        "  correct = (rounded_preds == y).float()  #convert into float for division \n",
        "  acc = correct.sum() / len(correct)\n",
        "  return acc"
      ],
      "metadata": {
        "id": "aD4BV0xuD6wW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Model\n",
        "\n",
        "Finally, the actual training of the sentiment analysis model. The `count_parameters` function is used to calculate the number of trainable parameters. `train` function is used to train each epoch of the model and so is the `evaluate` function to test or evaluate the trained model. `epoch_time` returns the execution time for each epoch."
      ],
      "metadata": {
        "id": "gmV8-0LcAfWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_DIM = len(vocab.keys())\n",
        "EMBED_DIM = 100\n",
        "HIDDEN_DIM = 128\n",
        "OUTPUT_DIM = 1\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "model = SentimentAnalysis(INPUT_DIM, EMBED_DIM, HIDDEN_DIM, OUTPUT_DIM)"
      ],
      "metadata": {
        "id": "wlZBnfFl_ivP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "metadata": {
        "id": "DM4rgINvAASV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4eeeffe-205f-49fe-a152-9ca0c5f1f654"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 9,596,969 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def collate_fn(batch):\n",
        "  labels, text = [], []\n",
        "  for label, line in batch:\n",
        "    labels.append(label)\n",
        "    text.append(torch.tensor(word_to_index(line)))\n",
        "  text = pad_sequence(text, padding_value=vocab['<PAD>'])\n",
        "  labels = torch.tensor(labels).to(device)\n",
        "  text = torch.tensor(text).to(device)\n",
        "  return labels, text"
      ],
      "metadata": {
        "id": "1ddhMXwXRbLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_iterator, batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=True)\n",
        "test_dataloader = DataLoader(test_iterator, batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=True)"
      ],
      "metadata": {
        "id": "UyJLMs-TRbOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model.to(device)\n",
        "criterion.to(device)"
      ],
      "metadata": {
        "id": "gBFoyMv2AlTQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77c01607-52bb-4160-c921-811e5da7ab57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BCEWithLogitsLoss()"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, dataloader, optimizer, criterion):\n",
        "  epoch_loss = 0\n",
        "  epoch_accuracy = 0\n",
        "  batch_idx = 0\n",
        "  model.train()\n",
        "  for labels, text in dataloader:\n",
        "    optimizer.zero_grad()\n",
        "    predictions = model(text).squeeze(1)\n",
        "    loss = criterion(predictions, labels.float())\n",
        "    accuracy = binary_accuracy(predictions, labels.float())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    epoch_loss += loss\n",
        "    epoch_accuracy += accuracy\n",
        "    batch_idx += 1\n",
        "  return epoch_loss/batch_idx, epoch_accuracy/batch_idx"
      ],
      "metadata": {
        "id": "apXmmhylIkVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, dataloader, criterion):\n",
        "  epoch_loss = 0\n",
        "  epoch_accuracy = 0\n",
        "  batch_idx = 0\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for labels, text in dataloader:\n",
        "      predictions = model(text).squeeze(1)\n",
        "      loss = criterion(predictions, labels.float())\n",
        "      accuracy = binary_accuracy(predictions, labels.float())\n",
        "      epoch_loss += loss\n",
        "      epoch_accuracy += accuracy\n",
        "      batch_idx += 1\n",
        "  return epoch_loss/batch_idx, epoch_accuracy/batch_idx"
      ],
      "metadata": {
        "id": "YPdYsCMdOqUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "vKQ3qJ-VPy0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "CLIP = 1\n",
        "\n",
        "if not os.path.exists('./../models'):\n",
        "  os.mkdir('./../models')"
      ],
      "metadata": {
        "id": "ehC83pm0Py2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_train_loss = float('inf')\n",
        "for epoch in range(EPOCHS):\n",
        "  start_time = time.time()\n",
        "  train_loss, train_acc = train(model, train_dataloader, optimizer, criterion)\n",
        "  end_time = time.time()\n",
        "  epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "  if train_loss < best_train_loss:\n",
        "      best_train_loss = train_loss\n",
        "      torch.save(model.state_dict(), './../models/sentimet-basic.pt')\n",
        "  print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}:{epoch_secs} | Train Accuracy: {train_acc:.3f} | Train Loss: {train_loss:.3f}')"
      ],
      "metadata": {
        "id": "Hbo44T_oPy5q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "312ca3f3-58ee-4fba-a860-1eff60a277d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-b8795c5dbc72>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  text = torch.tensor(text).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Time: 0:11 | Train Accuracy: 0.493 | Train Loss: -11.910\n",
            "Epoch: 02 | Time: 0:7 | Train Accuracy: 0.499 | Train Loss: -24.442\n",
            "Epoch: 03 | Time: 0:7 | Train Accuracy: 0.499 | Train Loss: -36.168\n",
            "Epoch: 04 | Time: 0:7 | Train Accuracy: 0.499 | Train Loss: -47.604\n",
            "Epoch: 05 | Time: 0:6 | Train Accuracy: 0.500 | Train Loss: -59.028\n",
            "Epoch: 06 | Time: 0:8 | Train Accuracy: 0.499 | Train Loss: -70.456\n",
            "Epoch: 07 | Time: 0:6 | Train Accuracy: 0.499 | Train Loss: -81.699\n",
            "Epoch: 08 | Time: 0:8 | Train Accuracy: 0.499 | Train Loss: -92.968\n",
            "Epoch: 09 | Time: 0:9 | Train Accuracy: 0.499 | Train Loss: -104.288\n",
            "Epoch: 10 | Time: 0:7 | Train Accuracy: 0.499 | Train Loss: -115.571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = evaluate(model, test_dataloader, criterion)\n",
        "\n",
        "print(f'Test Accuracy: {test_acc:.3f} | Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHoHDUemDNXZ",
        "outputId": "f9a9c873-aced-4ca2-8b25-2dc7d44babca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-b8795c5dbc72>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  text = torch.tensor(text).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.500 | Test Loss: -121.015 | Test PPL:   0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "\n",
        "- [IMDB Movie Review Dataset](http://ai.stanford.edu/~amaas/data/sentiment/)"
      ],
      "metadata": {
        "id": "T8-Dq8pPENhH"
      }
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}