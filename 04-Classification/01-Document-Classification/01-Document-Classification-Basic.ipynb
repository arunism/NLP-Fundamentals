{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfbpGVK2tmh9"
      },
      "source": [
        "# Document Classification\n",
        "\n",
        "Document classification is a process that involves assigning a label/category to an untagged document from predetermined sets of categories depending on its content."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchtext.datasets import AG_NEWS\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import SGD, lr_scheduler\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torch.utils.data.dataset import random_split\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.data.functional import to_map_style_dataset"
      ],
      "metadata": {
        "id": "xbLmL1LatqWk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torchdata"
      ],
      "metadata": {
        "id": "FonDjLntuMjO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "qHRHGX_BzQj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_iter, test_iter = AG_NEWS()\n",
        "tokenizer = get_tokenizer('basic_english')"
      ],
      "metadata": {
        "id": "4iSSVr1huZ5F"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tokens(data_iter):\n",
        "  for _, text in data_iter:\n",
        "    yield tokenizer(text)"
      ],
      "metadata": {
        "id": "1wE8N3cx0KSg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "specials = ['<UNK>', '<PAD>']\n",
        "vocab = build_vocab_from_iterator(get_tokens(train_iter), specials=specials)\n",
        "vocab.set_default_index(vocab[\"<UNK>\"])\n",
        "# vocab(['<UNK>'])"
      ],
      "metadata": {
        "id": "3oEY9shz0WAC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_pipeline = lambda x: vocab(tokenizer(x))\n",
        "label_pipeline = lambda x: int(x) - 1\n",
        "\n",
        "# text_pipeline('<UNK>')\n",
        "# label_pipeline('10')"
      ],
      "metadata": {
        "id": "AIkBJXAQr_Xx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = to_map_style_dataset(train_iter)\n",
        "test_data = to_map_style_dataset(test_iter)\n",
        "num_train = int(len(train_data) * 0.95)\n",
        "train_data, valid_data = random_split(train_data, [num_train, len(train_data) - num_train])"
      ],
      "metadata": {
        "id": "omO4r0y3X0Go"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "LR = 5\n",
        "BATCH_SIZE = 64\n",
        "NUM_CLASSES = len(set([label for (label, text) in train_iter]))\n",
        "VOCAB_SIZE = len(vocab)\n",
        "EMBED_SIZE = 64\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "ujs-gdeaYE4m"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "  label_list, text_list, offsets = [], [], [0]\n",
        "  for (_label, _text) in batch:\n",
        "    label_list.append(label_pipeline(_label))\n",
        "    processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
        "    text_list.append(processed_text)\n",
        "    offsets.append(processed_text.size(0))\n",
        "  label_list = torch.tensor(label_list, dtype=torch.int64)\n",
        "  offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "  text_list = torch.cat(text_list)\n",
        "  return label_list.to(device), text_list.to(device), offsets.to(device)"
      ],
      "metadata": {
        "id": "67D7bzWMX3Ng"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
        "valid_dataloader = DataLoader(valid_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
        "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "_5Nh5wTjX6kV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Definition"
      ],
      "metadata": {
        "id": "OqTm7B4rVOby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextClassificationModel(nn.Module):\n",
        "  def __init__(self, vocab_size, embed_dim, num_class):\n",
        "    super(TextClassificationModel, self).__init__()\n",
        "    self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
        "    self.fc = nn.Linear(embed_dim, num_class)\n",
        "    self.init_weights()\n",
        "\n",
        "  def init_weights(self):\n",
        "    initrange = 0.5\n",
        "    self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "    self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "    self.fc.bias.data.zero_()\n",
        "\n",
        "  def forward(self, text, offsets):\n",
        "    embedded = self.embedding(text, offsets)\n",
        "    return self.fc(embedded)"
      ],
      "metadata": {
        "id": "7Agody98VNud"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training"
      ],
      "metadata": {
        "id": "kWuqGX3MVxEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = TextClassificationModel(VOCAB_SIZE, EMBED_SIZE, NUM_CLASSES).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = SGD(model.parameters(), lr=LR)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)"
      ],
      "metadata": {
        "id": "FbGViLFMV08k"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader):\n",
        "  model.train()\n",
        "  total_loss, total_acc, total_count = 0, 0, 0\n",
        "  for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "    optimizer.zero_grad()\n",
        "    predicted_label = model(text, offsets)\n",
        "    loss = criterion(predicted_label, label)\n",
        "    loss.backward()\n",
        "    clip_grad_norm_(model.parameters(), 0.1)\n",
        "    optimizer.step()\n",
        "    total_loss += loss.item()\n",
        "    total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
        "    total_count += label.size(0)\n",
        "  return total_loss/total_count, total_acc/total_count"
      ],
      "metadata": {
        "id": "fpduadcxsaUX"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(dataloader):\n",
        "  model.eval()\n",
        "  total_loss, total_acc, total_count = 0, 0, 0\n",
        "  with torch.no_grad():\n",
        "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "      predicted_label = model(text, offsets)\n",
        "      loss = criterion(predicted_label, label)\n",
        "      total_loss += loss.item()\n",
        "      total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
        "      total_count += label.size(0)\n",
        "  return total_loss/total_count, total_acc/total_count"
      ],
      "metadata": {
        "id": "PhLUPRnLvkqH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('./../models'):\n",
        "  os.mkdir('./../models')\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "for epoch in range(EPOCHS):\n",
        "  start_time = time.time()\n",
        "  train_loss, train_acc = train(train_dataloader)\n",
        "  val_loss, val_acc = evaluate(valid_dataloader)\n",
        "  if val_loss < best_valid_loss:\n",
        "    best_valid_loss = val_loss\n",
        "    torch.save(model.state_dict(), './../models/doc-basic.pt')\n",
        "  print(f'Epoch: {epoch+1:02} | Time: {time.time()-start_time} | Train Loss: {train_loss:.3f} | Val Loss: {val_loss:.3f}')"
      ],
      "metadata": {
        "id": "hImrO5_pwnM2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c36da1c7-fd8c-44fb-c3e5-ffc635dc5b9f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Time: 9.047109127044678 | Train Loss: 0.007 | Val Loss: 0.005\n",
            "Epoch: 02 | Time: 7.889991760253906 | Train Loss: 0.004 | Val Loss: 0.005\n",
            "Epoch: 03 | Time: 8.327462911605835 | Train Loss: 0.004 | Val Loss: 0.004\n",
            "Epoch: 04 | Time: 7.527512073516846 | Train Loss: 0.003 | Val Loss: 0.005\n",
            "Epoch: 05 | Time: 8.903427839279175 | Train Loss: 0.003 | Val Loss: 0.005\n",
            "Epoch: 06 | Time: 8.236012935638428 | Train Loss: 0.003 | Val Loss: 0.006\n",
            "Epoch: 07 | Time: 7.583796739578247 | Train Loss: 0.003 | Val Loss: 0.005\n",
            "Epoch: 08 | Time: 8.807356834411621 | Train Loss: 0.003 | Val Loss: 0.005\n",
            "Epoch: 09 | Time: 8.494863271713257 | Train Loss: 0.002 | Val Loss: 0.006\n",
            "Epoch: 10 | Time: 8.160791873931885 | Train Loss: 0.002 | Val Loss: 0.006\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Test"
      ],
      "metadata": {
        "id": "xuG-XqDbX-C6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = evaluate(test_dataloader)\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Accuracy: {test_acc:.3f}')"
      ],
      "metadata": {
        "id": "YaUNDazS-Zi8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a39d1523-ff53-4f2b-b90b-4401788f3fd1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.006 | Test Accuracy: 0.889\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inferencing"
      ],
      "metadata": {
        "id": "tey7SzYBYm-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(text, text_pipeline):\n",
        "  with torch.no_grad():\n",
        "    text = torch.tensor(text_pipeline(text))\n",
        "    output = model(text, torch.tensor([0]))\n",
        "    return output.argmax(1).item() + 1"
      ],
      "metadata": {
        "id": "SWyeG9j5YmI4"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news_labels = {1: 'World', 2: 'Sports', 3: 'Business', 4: 'Sci/Tech'}\n",
        "model = model.to('cpu')\n",
        "\n",
        "text = 'The DJ used two artificial intelligence sites to create lyrics and a rap in the style of \\\n",
        "        the US star for a live show. The French producer has said he will not release the track commercially. \\\n",
        "        But he said he thinks musicians will use AI as a tool to create new sounds in the future, because \\\n",
        "        every new music style comes from a new technology.'\n",
        "\n",
        "print(f\"{news_labels[predict(text, text_pipeline)]} News\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u14xFpHoZ148",
        "outputId": "bbb40144-1ef8-4412-bbea-5d3da588d86d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "World News\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "\n",
        "- [Text Classification with the TorchText Library](https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html#split-the-dataset-and-run-the-model)\n",
        "- [Text Classification: Papers with code](https://paperswithcode.com/task/text-classification)"
      ],
      "metadata": {
        "id": "ALrDp4cIblaZ"
      }
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}