{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNZXeN2p9kR2qt86Ogmmw4Z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Document Classification using Hierarchical Attention Network"],"metadata":{"id":"jqyJ5NGrXR1J"}},{"cell_type":"code","source":["# !pip install torchdata"],"metadata":{"id":"aQR_BVMdZEEM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torchtext.datasets import AG_NEWS\n","from torch.utils.data import DataLoader\n","from torchtext.data.utils import get_tokenizer\n","from torch.utils.data.dataset import random_split\n","from torchtext.vocab import build_vocab_from_iterator\n","from torchtext.data.functional import to_map_style_dataset"],"metadata":{"id":"rRx35vSsXkk6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Preprocessing"],"metadata":{"id":"8CVZX_snZPJ6"}},{"cell_type":"code","source":["train_iter, test_iter = AG_NEWS()\n","tokenizer = get_tokenizer('basic_english')"],"metadata":{"id":"lTYUPRrAXzni"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_tokens(data_iter):\n","  for _, text in data_iter:\n","    yield tokenizer(text)"],"metadata":{"id":"BWJ3Y1qhajIK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["specials = ['<PAD>', '<UNK>']\n","vocab = build_vocab_from_iterator(get_tokens(train_iter), specials=specials)\n","vocab.set_default_index(vocab['<UNK>'])\n","# vocab(['<UNK>'])"],"metadata":{"id":"H9WnSgMabGYp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text_pipeline = lambda x: vocab(tokenizer(x))\n","label_pipeline = lambda x: int(x) - 1\n","\n","# text_pipeline('')\n","# label_pipeline('10')"],"metadata":{"id":"ietPR7ytbGbr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data = to_map_style_dataset(train_iter)\n","test_data = to_map_style_dataset(test_iter)\n","num_train = int(len(train_data) * 0.95)\n","train_data, valid_data = random_split(train_data, [num_train, len(train_data) - num_train])"],"metadata":{"id":"n4Q8BHOKbGja"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["EPOCHS = 10\n","LR = 5\n","BATCH_SIZE = 64\n","NUM_CLASSES = len(set([label for (label, text) in train_iter]))\n","VOCAB_SIZE = len(vocab)\n","EMBED_SIZE = 64\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"hmP2xD5kbGnX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def collate_fn(batch):\n","  label_list, text_list, offsets = [], [], [0]\n","  for (_label, _text) in batch:\n","    label_list.append(label_pipeline(_label))\n","    processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n","    text_list.append(processed_text)\n","    offsets.append(processed_text.size(0))\n","  label_list = torch.tensor(label_list, dtype=torch.int64)\n","  offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n","  text_list = torch.cat(text_list)\n","  return label_list.to(device), text_list.to(device), offsets.to(device)"],"metadata":{"id":"LV0ZW3eWbGqD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n","valid_dataloader = DataLoader(valid_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n","test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)"],"metadata":{"id":"ctkEM4NHbwj3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Model Definition"],"metadata":{"id":"g3-WQcY2ZRoD"}},{"cell_type":"code","source":["class WordAttention(nn.Module):\n","  def __init__(self):\n","    super().__init__()"],"metadata":{"id":"nOWNdYhBFg5G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class HAN(nn.Module):\n","  def __init__(self, inp_dim, emb_dim, word_hid_dim, sent_hid_dim):\n","    super().__init__()\n","  \n","  def forward(self, inp, lock_dropout):\n","    batch_size = inp.shape[0]"],"metadata":{"id":"a9Ssq--_XzqB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676469796135,"user_tz":-345,"elapsed":590,"user":{"displayName":"Arun Ghimire","userId":"12379322823635086573"}},"outputId":"eb2cf2b7-3577-45ea-e092-4fe36de0715b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2781])\n"]}]},{"cell_type":"markdown","source":["## Model Training"],"metadata":{"id":"AXytWY00ZUqa"}},{"cell_type":"code","source":[],"metadata":{"id":"mZf81zo1xvHo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"KiVOa5ybXzsX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"1SfplNiYXzvz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## References\n","\n","- [Hierarchical Attention Network for Document Classification](https://aclanthology.org/N16-1174.pdf)\n","- [Hierarchical Sentiment](https://github.com/cedias/Hierarchical-Sentiment)"],"metadata":{"id":"_GLE6inQXz5U"}}]}